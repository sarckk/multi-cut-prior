{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "488995e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.began import Generator128\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "import argparse\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bd62bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cba20aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['enc.l0.weight', 'enc.l0.bias', 'enc.l1.weight', 'enc.l1.bias', 'enc.l2.weight', 'enc.l2.bias', 'enc.down1.weight', 'enc.down1.bias', 'enc.l3.weight', 'enc.l3.bias', 'enc.l4.weight', 'enc.l4.bias', 'enc.down2.weight', 'enc.down2.bias', 'enc.l5.weight', 'enc.l5.bias', 'enc.l6.weight', 'enc.l6.bias', 'enc.down3.weight', 'enc.down3.bias', 'enc.l7.weight', 'enc.l7.bias', 'enc.l8.weight', 'enc.l8.bias', 'enc.down4.weight', 'enc.down4.bias', 'enc.l9.weight', 'enc.l9.bias', 'enc.l11.weight', 'enc.l11.bias', 'enc.l12.weight', 'enc.l12.bias', 'dec.l0.weight', 'dec.l0.bias', 'dec.l1.weight', 'dec.l1.bias', 'dec.l2.weight', 'dec.l2.bias', 'dec.l3.weight', 'dec.l3.bias', 'dec.l4.weight', 'dec.l4.bias', 'dec.l5.weight', 'dec.l5.bias', 'dec.l6.weight', 'dec.l6.bias', 'dec.l7.weight', 'dec.l7.bias', 'dec.l8.weight', 'dec.l8.bias', 'dec.l10.weight', 'dec.l10.bias', 'dec.l11.weight', 'dec.l11.bias', 'dec.l9.weight', 'dec.l9.bias'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load('./trained_model/disc_208000.pth', map_location='cuda:0')\n",
    "state_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39a1ca8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.predictor import PredictorBEGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3cb6e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = PredictorBEGAN()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a969594",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pred(torch.rand(1,3,128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c5ef0bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 8, 8])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cacf077a",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load('./trained_model/gen_208000.pth', map_location='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6b80c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['l0.weight', 'l0.bias', 'l1.weight', 'l1.bias', 'l2.weight', 'l2.bias', 'l3.weight', 'l3.bias', 'l4.weight', 'l4.bias', 'l5.weight', 'l5.bias', 'l6.weight', 'l6.bias', 'l7.weight', 'l7.bias', 'l8.weight', 'l8.bias', 'l10.weight', 'l10.bias', 'l11.weight', 'l11.bias', 'l9.weight', 'l9.bias'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec8873b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class View(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super().__init__()\n",
    "        self.shape = shape\n",
    "\n",
    "    def forward(self, input):\n",
    "        return input.view(*self.shape)\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    All convs are created with:\n",
    "    conv(in_channel, out_channel, kernel, stride, pad, bias)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch, out_ch, k, s, p, b):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_ch,\n",
    "                      out_ch,\n",
    "                      kernel_size=k,\n",
    "                      stride=s,\n",
    "                      padding=p,\n",
    "                      bias=b), nn.ELU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.ch = 128\n",
    "        self.latent_dim = 64\n",
    "        self.scale_size = 128\n",
    "        self.initial_size = 8\n",
    "        \n",
    "        self.layers = nn.ModuleList([\n",
    "             nn.Sequential(\n",
    "                nn.Linear(self.latent_dim,\n",
    "                          self.initial_size**2 * self.ch,\n",
    "                          bias=True),\n",
    "                View((-1, self.ch, self.initial_size, self.initial_size))\n",
    "             ),\n",
    "            \n",
    "            # first block\n",
    "            ConvBlock(self.ch, self.ch, 3, 1, 1, True),\n",
    "            ConvBlock(self.ch, self.ch, 3, 1, 1, True),\n",
    "            \n",
    "            # second block\n",
    "            nn.UpsamplingNearest2d(scale_factor=2),\n",
    "            ConvBlock(self.ch, self.ch, 3, 1, 1, True),\n",
    "            ConvBlock(self.ch, self.ch, 3, 1, 1, True),\n",
    "            \n",
    "            # third block\n",
    "            nn.UpsamplingNearest2d(scale_factor=2),\n",
    "            ConvBlock(self.ch, self.ch, 3, 1, 1, True),\n",
    "            ConvBlock(self.ch, self.ch, 3, 1, 1, True),\n",
    "            \n",
    "            # fourth block\n",
    "            nn.UpsamplingNearest2d(scale_factor=2),\n",
    "            ConvBlock(self.ch, self.ch, 3, 1, 1, True),\n",
    "            ConvBlock(self.ch, self.ch, 3, 1, 1, True),\n",
    "            \n",
    "            # fifth block\n",
    "            nn.UpsamplingNearest2d(scale_factor=2),\n",
    "            ConvBlock(self.ch, self.ch, 3, 1, 1, True),\n",
    "            ConvBlock(self.ch, self.ch, 3, 1, 1, True),\n",
    "            \n",
    "            # last block\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(self.ch, 3, 3, 1, 1),\n",
    "                nn.Tanh()\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        self.input_shapes = [\n",
    "            # Raw input shape\n",
    "            ((self.latent_dim, ), ()),\n",
    "\n",
    "            # Skip Linear+View()\n",
    "            ((128, 8, 8), ()),\n",
    "\n",
    "            # First block\n",
    "            ((128, 8, 8), ()),\n",
    "            ((128, 8, 8), ()),\n",
    "\n",
    "            # Second conv\n",
    "            ((128, 16, 16), ()),\n",
    "            ((128, 16, 16), ()),\n",
    "            ((128, 16, 16), ()),\n",
    "\n",
    "            # Third conv\n",
    "            ((128, 32, 32), ()),\n",
    "            ((128, 32, 32), ()),\n",
    "            ((128, 32, 32), ()),\n",
    "             \n",
    "            # Fourth conv\n",
    "            ((128, 64, 64), ()),\n",
    "            ((128, 64, 64), ()),\n",
    "            ((128, 64, 64), ()),\n",
    "             \n",
    "            # Fifth conv\n",
    "            ((128, 128, 128), ()),\n",
    "            ((128, 128, 128), ()),\n",
    "            ((128, 128, 128), ()),\n",
    "\n",
    "            # Skip the whole net\n",
    "            ((3, 128, 128), ()),\n",
    "        ]\n",
    "#         self.l0 = nn.Linear(self.h, 8*8*self.num_channel)\n",
    "#         self.l1 = nn.Conv2d(self.num_channel, self.num_channel, 3, 1, 1)\n",
    "#         self.l2 = nn.Conv2d(self.num_channel, self.num_channel, 3, 1, 1)\n",
    "#         self.up1 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "#         self.l3 = nn.Conv2d(self.num_channel, self.num_channel, 3, 1, 1)\n",
    "#         self.l4 = nn.Conv2d(self.num_channel, self.num_channel, 3, 1, 1)\n",
    "#         self.up2 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "#         self.l5 = nn.Conv2d(self.num_channel, self.num_channel, 3, 1, 1)\n",
    "#         self.l6 = nn.Conv2d(self.num_channel, self.num_channel, 3, 1, 1)\n",
    "#         self.up3 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "#         self.l7 = nn.Conv2d(self.num_channel, self.num_channel, 3, 1, 1)\n",
    "#         self.l8 = nn.Conv2d(self.num_channel, self.num_channel, 3, 1, 1)\n",
    "#         if self.scale_size == 128:\n",
    "#             self.up4 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "#             self.l10 = nn.Conv2d(self.num_channel, self.num_channel, 3, 1, 1)\n",
    "#             self.l11 = nn.Conv2d(self.num_channel, self.num_channel, 3, 1, 1)\n",
    "#         self.l9 = nn.Conv2d(self.num_channel, 3, 3, 1, 1)\n",
    "        \n",
    "        self._check_input_shapes()\n",
    "        \n",
    "    def _check_input_shapes(self):\n",
    "        for n_cuts, (x1_shape, x2_shape) in enumerate(self.input_shapes):\n",
    "            print(n_cuts)\n",
    "            x1 = torch.randn(1, *x1_shape)\n",
    "            if n_cuts <= 1:\n",
    "                x2 = None\n",
    "            else:\n",
    "                x2 = torch.randn(1, *x2_shape)\n",
    "            res = self.forward(x1, x2, n_cuts)\n",
    "            print(x1.shape, () if n_cuts <= 1 else x2.shape, res.shape[1:])\n",
    "            \n",
    "\n",
    "    def forward(self, z, z2=None, n_cuts=0, end=None):\n",
    "        if end is None:\n",
    "            end = len(self.layers)\n",
    "        for i, layer in enumerate(self.layers[n_cuts:end]):\n",
    "            z = layer(z)\n",
    "        return z\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'Began.Gen128.latent_dim={self.latent_dim}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "295c3d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([1, 64]) () torch.Size([3, 128, 128])\n",
      "1\n",
      "torch.Size([1, 128, 8, 8]) () torch.Size([3, 128, 128])\n",
      "2\n",
      "torch.Size([1, 128, 8, 8]) torch.Size([1]) torch.Size([3, 128, 128])\n",
      "3\n",
      "torch.Size([1, 128, 8, 8]) torch.Size([1]) torch.Size([3, 128, 128])\n",
      "4\n",
      "torch.Size([1, 128, 16, 16]) torch.Size([1]) torch.Size([3, 128, 128])\n",
      "5\n",
      "torch.Size([1, 128, 16, 16]) torch.Size([1]) torch.Size([3, 128, 128])\n",
      "6\n",
      "torch.Size([1, 128, 16, 16]) torch.Size([1]) torch.Size([3, 128, 128])\n",
      "7\n",
      "torch.Size([1, 128, 32, 32]) torch.Size([1]) torch.Size([3, 128, 128])\n",
      "8\n",
      "torch.Size([1, 128, 32, 32]) torch.Size([1]) torch.Size([3, 128, 128])\n",
      "9\n",
      "torch.Size([1, 128, 32, 32]) torch.Size([1]) torch.Size([3, 128, 128])\n",
      "10\n",
      "torch.Size([1, 128, 64, 64]) torch.Size([1]) torch.Size([3, 128, 128])\n",
      "11\n",
      "torch.Size([1, 128, 64, 64]) torch.Size([1]) torch.Size([3, 128, 128])\n",
      "12\n",
      "torch.Size([1, 128, 64, 64]) torch.Size([1]) torch.Size([3, 128, 128])\n",
      "13\n",
      "torch.Size([1, 128, 128, 128]) torch.Size([1]) torch.Size([3, 128, 128])\n",
      "14\n",
      "torch.Size([1, 128, 128, 128]) torch.Size([1]) torch.Size([3, 128, 128])\n",
      "15\n",
      "torch.Size([1, 128, 128, 128]) torch.Size([1]) torch.Size([3, 128, 128])\n",
      "16\n",
      "torch.Size([1, 3, 128, 128]) torch.Size([1]) torch.Size([3, 128, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (layers): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=8192, bias=True)\n",
       "      (1): View()\n",
       "    )\n",
       "    (1): ConvBlock(\n",
       "      (net): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "    (2): ConvBlock(\n",
       "      (net): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "    (3): UpsamplingNearest2d(scale_factor=2.0, mode=nearest)\n",
       "    (4): ConvBlock(\n",
       "      (net): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "    (5): ConvBlock(\n",
       "      (net): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "    (6): UpsamplingNearest2d(scale_factor=2.0, mode=nearest)\n",
       "    (7): ConvBlock(\n",
       "      (net): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "    (8): ConvBlock(\n",
       "      (net): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "    (9): UpsamplingNearest2d(scale_factor=2.0, mode=nearest)\n",
       "    (10): ConvBlock(\n",
       "      (net): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "    (11): ConvBlock(\n",
       "      (net): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "    (12): UpsamplingNearest2d(scale_factor=2.0, mode=nearest)\n",
       "    (13): ConvBlock(\n",
       "      (net): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "    (14): ConvBlock(\n",
       "      (net): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "    (15): Sequential(\n",
       "      (0): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = Decoder()\n",
    "gen.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e26ac16",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_to_new = {\n",
    "    'l0': 'layers.0.0', # linear\n",
    "    'l1': 'layers.1.net.0',\n",
    "    'l2': 'layers.2.net.0',\n",
    "    'l3': 'layers.4.net.0',\n",
    "    'l4': 'layers.5.net.0',\n",
    "    'l5': 'layers.7.net.0',\n",
    "    'l6': 'layers.8.net.0',\n",
    "    'l7': 'layers.10.net.0',\n",
    "    'l8': 'layers.11.net.0',\n",
    "    'l9': 'layers.15.0',\n",
    "    'l10': 'layers.13.net.0',\n",
    "    'l11': 'layers.14.net.0',\n",
    "}\n",
    "    \n",
    "def _rename_state_dict(name_mapping, state_dict):\n",
    "    # rename layers\n",
    "    for key in list(state_dict.keys()):\n",
    "        layer = key.split('.')[0]\n",
    "        rest = key.split('.')[1]\n",
    "        new_key = name_mapping[layer] + '.' + rest\n",
    "        state_dict[new_key] = state_dict[key]\n",
    "        del state_dict[key]\n",
    "      \n",
    "    return state_dict\n",
    "\n",
    "state_dict = _rename_state_dict(old_to_new, state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "100b6234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93fc9970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generative_experiments(obj):\n",
    "    z = []\n",
    "    for inter in range(10):\n",
    "        z0 = np.random.uniform(-1,1,64)\n",
    "        z10 = np.random.uniform(-1,1,64)\n",
    "        def slerp(val, low, high):\n",
    "            omega = np.arccos(np.clip(np.dot(low/np.linalg.norm(low), high/np.linalg.norm(high)), -1, 1))\n",
    "            so = np.sin(omega)\n",
    "            if so == 0:\n",
    "                return (1.0-val) * low + val * high # L'Hopital's rule/LERP\n",
    "            return np.sin((1.0-val)*omega) / so * low + np.sin(val*omega) / so * high \n",
    "\n",
    "        z.append(z0)\n",
    "        for i in range(1, 9):\n",
    "            z.append(slerp(i*0.1, z0, z10))\n",
    "        z.append(z10.reshape(1, 64)) \n",
    "    z = [_.reshape(1, 64) for _ in z]\n",
    "    z_var = Variable(torch.from_numpy(np.concatenate(z, 0)).float())\n",
    "    z_var = z_var.cuda()\n",
    "    gen_z = obj(z_var)\n",
    "    vutils.save_image(gen_z.data, '%s_%s_gen.png'%('began', 12), nrow=10, normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cbc7073",
   "metadata": {},
   "outputs": [],
   "source": [
    "generative_experiments(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13b9ab9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ab49e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b32c2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9850e46f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548462b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310dfb7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
